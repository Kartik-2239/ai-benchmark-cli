[
    {
        "question": "How do machine learning models learn from data?",
        "answers": [
            "by finding mathematical relationships between input and output data through training",
            "by adjusting model parameters using backpropagation and gradient descent",
            "by learning patterns from labeled or unlabeled examples in the training dataset",
            "by minimizing the loss function which measures the error between predictions and true labels"
        ],
        "negative_answers": [
            "by explicitly programming all rules for every scenario",
            "by copying patterns directly from memory without learning relationships",
            "by random guessing without any systematic optimization",
            "by memorizing every single example exactly as it appears"
        ]
    },
    {
        "question": "What is the role of activation functions in neural networks?",
        "answers": [
            "they introduce non-linearity to allow networks to learn complex patterns",
            "they enable deeper networks by preventing vanishing/exploding gradients",
            "they transform linear combinations into non-linear outputs",
            "ReLU is popular because it avoids the vanishing gradient problem"
        ],
        "negative_answers": [
            "they make linear models more powerful without changing their properties",
            "they are only needed for the output layer",
            "they replace the need for multiple layers in neural networks",
            "sigmoid and tanh are always better than ReLU for all tasks"
        ]
    },
    {
        "question": "How does backpropagation work in neural networks?",
        "answers": [
            "it propagates errors backward through the network layer by layer",
            "it computes gradients of the loss function with respect to each parameter using the chain rule",
            "it enables efficient gradient calculation for optimization",
            "it uses the computed gradients to update weights via gradient descent"
        ],
        "negative_answers": [
            "it trains the network by randomly adjusting weights",
            "it only works for the last layer of the network",
            "it requires calculating gradients for each sample separately without optimization",
            "it is the same as forward propagation done in reverse"
        ]
    },
    {
        "question": "What is the attention mechanism in transformers?",
        "answers": [
            "it allows models to focus on different parts of input when processing each token",
            "it uses query, key, and value matrices to compute weighted relationships",
            "it captures long-range dependencies better than RNNs",
            "it enables parallel processing of entire sequences instead of sequential processing"
        ],
        "negative_answers": [
            "it randomly selects which parts of the input to process",
            "it requires processing the input sequentially like RNNs",
            "it is a fixed weighting scheme for all tokens",
            "it only works for short sequences due to computational constraints"
        ]
    },
    {
        "question": "How do large language models learn language patterns?",
        "answers": [
            "by pre-training on massive text datasets using next-token prediction",
            "by learning to predict the next word given previous words",
            "through self-attention mechanisms that capture word relationships",
            "by fine-tuning on specific tasks with labeled data after pre-training"
        ],
        "negative_answers": [
            "by memorizing specific examples from training data",
            "by following hardcoded grammar rules",
            "by reading and understanding books like humans do",
            "by having explicit knowledge of every word's meaning programmed in"
        ]
    },
    {
        "question": "What is transfer learning and why is it important?",
        "answers": [
            "it leverages knowledge from pre-trained models on large datasets for new tasks",
            "it reduces training time and data requirements for new tasks",
            "it allows using general features learned on one task for related tasks",
            "fine-tuning a pre-trained model is more efficient than training from scratch"
        ],
        "negative_answers": [
            "it is the same as training a new model from randomly initialized weights",
            "it cannot improve performance on small datasets",
            "pre-trained models are always worse than task-specific models",
            "it requires more data than training from scratch"
        ]
    },
    {
        "question": "How does dropout prevent overfitting?",
        "answers": [
            "by randomly deactivating neurons during training to prevent co-adaptation",
            "it forces the network to learn redundant representations",
            "it effectively trains multiple thinned networks that are averaged at test time",
            "it reduces the effective model capacity without reducing parameters"
        ],
        "negative_answers": [
            "it deletes features from the training data permanently",
            "it reduces model capacity by removing layers",
            "it is applied during inference to improve predictions",
            "it works by randomly removing samples from the training set"
        ]
    },
    {
        "question": "What is the difference between supervised and unsupervised learning?",
        "answers": [
            "supervised learning uses labeled data with input-output pairs",
            "unsupervised learning finds patterns in unlabeled data",
            "supervised learning predicts specific targets while unsupervised finds groupings",
            "unsupervised learning includes clustering and dimensionality reduction"
        ],
        "negative_answers": [
            "unsupervised learning is always better than supervised learning",
            "supervised learning cannot work with large datasets",
            "unsupervised models require more labeled examples than supervised models",
            "both are identical methods with different names"
        ]
    },
    {
        "question": "How does batch normalization accelerate training?",
        "answers": [
            "it normalizes layer inputs to have consistent distributions",
            "it reduces internal covariate shift during training",
            "it allows using higher learning rates for faster convergence",
            "it stabilizes training and reduces sensitivity to weight initialization"
        ],
        "negative_answers": [
            "it processes data in larger batches which is always faster",
            "it reduces the number of parameters in the network",
            "it is only applied at the end of training",
            "it eliminates the need for learning rate tuning"
        ]
    },
    {
        "question": "What is reinforcement learning and how does it differ from supervised learning?",
        "answers": [
            "it learns through trial and error using reward signals",
            "an agent takes actions and receives feedback as rewards or penalties",
            "it optimizes for long-term cumulative reward, not just immediate accuracy",
            "it can learn from its own interactions without labeled data"
        ],
        "negative_answers": [
            "it requires labeled input-output pairs like supervised learning",
            "the reward signal is given immediately for every action",
            "it is slower and less effective than supervised learning for all tasks",
            "it cannot learn useful behaviors without explicit instruction"
        ]
    },
    {
        "question": "How do convolutional neural networks (CNNs) process images?",
        "answers": [
            "they use convolutional filters to detect features at different spatial locations",
            "filters detect low-level features like edges and textures in early layers",
            "deeper layers combine features to detect higher-level patterns",
            "pooling layers downsample the feature maps to reduce computation"
        ],
        "negative_answers": [
            "they treat each pixel independently without considering spatial relationships",
            "they require the same number of parameters regardless of image size",
            "convolutional layers are not necessary for image processing",
            "filters are fixed and do not learn during training"
        ]
    },
    {
        "question": "What is the purpose of cross-entropy loss in classification?",
        "answers": [
            "it measures the dissimilarity between predicted and true probability distributions",
            "it penalizes confident wrong predictions more heavily",
            "it provides strong gradients for effective backpropagation",
            "it ensures probabilities sum to 1 when used with softmax"
        ],
        "negative_answers": [
            "it is only used for regression tasks",
            "it treats all misclassifications equally regardless of confidence",
            "it does not work with multi-class classification",
            "it produces zero gradients for incorrect predictions"
        ]
    },
    {
        "question": "How do transformers process sequences in parallel?",
        "answers": [
            "self-attention allows all positions to attend to all other positions simultaneously",
            "no recurrence is needed, enabling parallel processing across positions",
            "multi-head attention computes multiple attention patterns in parallel",
            "the entire sequence can be processed in a single forward pass"
        ],
        "negative_answers": [
            "transformers process sequences token-by-token like RNNs",
            "parallel processing is not an advantage of transformers",
            "transformers require sequential processing for efficiency",
            "attention computation is slower when done in parallel"
        ]
    },
    {
        "question": "What is fine-tuning and how does it differ from training from scratch?",
        "answers": [
            "fine-tuning starts with a pre-trained model and adjusts it for a new task",
            "only a small portion of parameters are updated in fine-tuning",
            "it requires much less training data than training from scratch",
            "learning rates are typically lower to avoid catastrophic forgetting"
        ],
        "negative_answers": [
            "fine-tuning resets all pre-trained weights to random values",
            "it always requires the same amount of data as training from scratch",
            "fine-tuned models are always less accurate than models trained from scratch",
            "fine-tuning is only useful for the same task as pre-training"
        ]
    },
    {
        "question": "How does embedding represent words in neural networks?",
        "answers": [
            "it converts discrete words into continuous vector representations",
            "words with similar meanings have embeddings that are close in vector space",
            "embeddings capture semantic and syntactic properties of words",
            "transformer embeddings are contextual and depend on surrounding words"
        ],
        "negative_answers": [
            "embeddings are one-hot encoded vectors of the same dimension as vocabulary",
            "all word embeddings are identical regardless of context",
            "embeddings do not capture any meaningful relationships between words",
            "static embeddings from word2vec are always better than contextual embeddings"
        ]
    },
    {
        "question": "What is the vanishing gradient problem and how is it solved?",
        "answers": [
            "gradients become very small in deep networks due to repeated multiplication",
            "this prevents lower layers from learning effectively",
            "ReLU activation helps by maintaining non-zero gradients",
            "LSTMs with gating mechanisms help preserve gradient flow"
        ],
        "negative_answers": [
            "it only affects very shallow networks with few layers",
            "sigmoid and tanh activation functions solve this problem completely",
            "gradient descent cannot work in deep networks",
            "the vanishing gradient problem has no practical solution"
        ]
    },
    {
        "question": "How does regularization prevent overfitting?",
        "answers": [
            "L1 and L2 regularization add penalty terms for large weights",
            "they discourage the model from learning overly complex patterns",
            "early stopping halts training when validation performance degrades",
            "data augmentation provides more diverse training examples"
        ],
        "negative_answers": [
            "regularization always improves training accuracy",
            "it is only useful when training data is very limited",
            "regularization techniques are mutually exclusive and should not be combined",
            "models with regularization converge faster than models without it"
        ]
    },
    {
        "question": "What is the softmax function and when is it used?",
        "answers": [
            "it converts logits into probability distributions for multi-class classification",
            "it ensures output probabilities sum to 1",
            "it is applied to the output layer for multi-class problems",
            "it provides a smooth gradient for all classes"
        ],
        "negative_answers": [
            "softmax is used for binary classification tasks",
            "it is applied before hidden layers in the network",
            "softmax probabilities do not need to sum to 1",
            "it is only useful for regression problems"
        ]
    },
    {
        "question": "How does RLHF (Reinforcement Learning from Human Feedback) work?",
        "answers": [
            "human annotators rank model outputs to provide preference signals",
            "a reward model learns to predict human preferences from rankings",
            "the language model is fine-tuned to maximize rewards using RL",
            "it helps align model behavior with human values"
        ],
        "negative_answers": [
            "it requires manual labeling of every possible output",
            "the reward model is not used after training",
            "RLHF always produces harmful outputs if not carefully implemented",
            "human feedback is unnecessary for model improvement"
        ]
    },
    {
        "question": "What is the difference between semantic and instance segmentation?",
        "answers": [
            "semantic segmentation assigns class labels to each pixel",
            "instance segmentation also distinguishes between different objects of the same class",
            "semantic segmentation treats all objects of a class as one entity",
            "instance segmentation is more fine-grained and complex"
        ],
        "negative_answers": [
            "both methods produce identical results for image analysis",
            "semantic segmentation can distinguish individual object instances",
            "instance segmentation only works for object detection tasks",
            "semantic segmentation requires bounding boxes like object detection"
        ]
    },
    {
        "question": "How do word2vec embeddings differ from transformer embeddings?",
        "answers": [
            "word2vec creates static embeddings where each word has one representation",
            "transformer embeddings are contextual and vary based on surrounding words",
            "word2vec embeddings are computed once during training",
            "transformer embeddings better capture polysemy and word sense"
        ],
        "negative_answers": [
            "word2vec embeddings are dynamic like transformer embeddings",
            "transformer embeddings are always trained faster than word2vec",
            "contextual information is not useful for word representation",
            "word2vec embeddings are always superior to transformer embeddings"
        ]
    },
    {
        "question": "What is hyperparameter tuning and why is it important?",
        "answers": [
            "it involves finding optimal values for parameters not learned from data",
            "examples include learning rate, batch size, number of layers",
            "grid search and random search are common tuning strategies",
            "proper tuning significantly improves model performance"
        ],
        "negative_answers": [
            "hyperparameters are learned automatically during training",
            "tuning hyperparameters has no impact on model performance",
            "there is only one correct set of hyperparameters for all problems",
            "random hyperparameters always work as well as tuned ones"
        ]
    },
    {
        "question": "How does data augmentation improve model generalization?",
        "answers": [
            "it artificially increases dataset diversity by applying transformations",
            "image augmentation includes rotation, flipping, cropping, color adjustments",
            "text augmentation uses synonym replacement and back-translation",
            "augmented data helps prevent overfitting by providing more examples"
        ],
        "negative_answers": [
            "data augmentation only works for image data",
            "augmented examples must be manually labeled like original data",
            "it decreases the effective size of the training dataset",
            "augmentation is only useful when training data is already very large"
        ]
    },
    {
        "question": "What is knowledge distillation and what are its benefits?",
        "answers": [
            "a student model learns to mimic a larger teacher model",
            "it enables model compression for edge device deployment",
            "the student achieves high accuracy with fewer parameters",
            "it transfers the knowledge of complex models to simpler ones"
        ],
        "negative_answers": [
            "knowledge distillation requires training the student model from scratch",
            "the student model always performs worse than the teacher",
            "it is only applicable to neural networks, not other models",
            "training time is always reduced when using knowledge distillation"
        ]
    },
    {
        "question": "How do RNNs, LSTMs, and GRUs differ for sequence modeling?",
        "answers": [
            "RNNs process sequences sequentially with hidden state connections",
            "LSTMs use gating mechanisms to handle long-term dependencies",
            "GRUs are simpler than LSTMs with fewer parameters",
            "transformers have replaced RNNs for many sequence tasks"
        ],
        "negative_answers": [
            "all three models have identical performance on sequence tasks",
            "LSTMs are always better than RNNs for every application",
            "GRUs are fundamentally different from LSTMs with different computation",
            "sequence models cannot be parallelized like transformers"
        ]
    },
    {
        "question": "What is prompt engineering and how does it improve LLM outputs?",
        "answers": [
            "it involves crafting input prompts to guide LLM behavior",
            "techniques include zero-shot, few-shot, and chain-of-thought prompting",
            "chain-of-thought breaks complex problems into step-by-step reasoning",
            "well-engineered prompts reduce ambiguity and improve accuracy"
        ],
        "negative_answers": [
            "prompt engineering modifies the model weights permanently",
            "all prompts produce identical outputs regardless of phrasing",
            "it is only useful for simple tasks with straightforward answers",
            "LLMs understand prompts identically to how humans read instructions"
        ]
    },
    {
        "question": "How do neural networks handle overfitting versus underfitting?",
        "answers": [
            "overfitting occurs when models memorize training data instead of generalizing",
            "underfitting means the model is too simple to capture patterns",
            "techniques like dropout and regularization reduce overfitting",
            "using more complex models and collecting more data helps underfitting"
        ],
        "negative_answers": [
            "overfitting and underfitting are the same phenomenon",
            "increasing model complexity always reduces overfitting",
            "underfitting is only a problem with small datasets",
            "training accuracy being high guarantees good test accuracy"
        ]
    },
    {
        "question": "What is the role of the query, key, and value in attention mechanism?",
        "answers": [
            "query represents what information is being looked for",
            "key represents what information each position contains",
            "value is the actual information contributed to the output",
            "attention weights are computed by matching queries to keys"
        ],
        "negative_answers": [
            "query, key, and value are identical matrices",
            "keys are not used in attention weight computation",
            "values are only used for one specific query",
            "the order of query, key, value operations does not matter"
        ]
    },
    {
        "question": "How does model interpretability help in machine learning?",
        "answers": [
            "LIME and SHAP explain individual predictions",
            "interpretability helps identify model biases and errors",
            "attention weights provide insight into model decision-making",
            "feature importance shows which inputs most influence predictions"
        ],
        "negative_answers": [
            "interpretable models always perform better than black-box models",
            "model performance and interpretability cannot be traded off",
            "only deep learning models lack interpretability",
            "interpretability is only important for regulatory compliance"
        ]
    },
    {
        "question": "What are the advantages and disadvantages of batch normalization?",
        "answers": [
            "advantages: faster training, allows higher learning rates, reduces initialization sensitivity",
            "disadvantages: computational overhead, changes behavior between train and test",
            "it works well for convolutional and feedforward networks",
            "layer normalization is preferred for transformers and RNNs"
        ],
        "negative_answers": [
            "batch normalization is always beneficial regardless of architecture",
            "it has no computational cost during inference",
            "batch normalization is not necessary when using dropout",
            "it works identically during training and inference"
        ]
    },
    {
        "question": "How does tokenization prepare text for neural networks?",
        "answers": [
            "it breaks text into tokens: words, subwords, or characters",
            "tokenization converts text into a format neural networks can process",
            "subword tokenization handles out-of-vocabulary words",
            "BERT uses WordPiece tokenization for efficient representation"
        ],
        "negative_answers": [
            "tokenization is optional for text processing",
            "all tokenization methods produce identical results",
            "character-level tokenization is always better than word-level",
            "neural networks can directly process raw text without tokenization"
        ]
    },
    {
        "question": "What is model convergence and how is it achieved?",
        "answers": [
            "convergence means the model's loss stops decreasing significantly",
            "it indicates the optimization has found a local minimum",
            "proper learning rate, batch size, and regularization promote convergence",
            "early stopping can prevent overfitting by stopping at convergence"
        ],
        "negative_answers": [
            "convergence guarantees the global minimum has been found",
            "continuing training after convergence always improves performance",
            "loss must reach zero for convergence to occur",
            "convergence is not important for model deployment"
        ]
    },
    {
        "question": "How do GANs (Generative Adversarial Networks) work?",
        "answers": [
            "a generator creates synthetic data from random noise",
            "a discriminator tries to distinguish real from generated data",
            "both networks improve through adversarial training",
            "GANs can generate realistic images, text, and other data"
        ],
        "negative_answers": [
            "the generator and discriminator have identical architectures",
            "the discriminator is discarded after training",
            "GANs always converge to a stable equilibrium",
            "GANs require labeled data for training"
        ]
    },
    {
        "question": "What are the differences between training, validation, and test sets?",
        "answers": [
            "training set is used to learn model parameters",
            "validation set helps tune hyperparameters and prevent overfitting",
            "test set provides final unbiased evaluation of model performance",
            "data leakage between sets produces misleading performance estimates"
        ],
        "negative_answers": [
            "all three sets are identical and interchangeable",
            "validation set should come from the test set",
            "training on test data is acceptable to maximize performance",
            "hyperparameter tuning on test set is a valid approach"
        ]
    },
    {
        "question": "How does explainable AI (XAI) benefit model development?",
        "answers": [
            "it reveals which features contribute most to predictions",
            "it helps detect biases, errors, and spurious correlations",
            "interpretability increases trust in model decisions",
            "it enables debugging and improving model behavior"
        ],
        "negative_answers": [
            "XAI is only required for regulatory compliance",
            "interpretability always reduces model performance",
            "explainable models are inherently more accurate",
            "model transparency is unnecessary for production systems"
        ]
    },
    {
        "question": "What is the difference between L1 and L2 regularization?",
        "answers": [
            "L1 (Lasso) regularization encourages sparse solutions by driving weights to zero",
            "L2 (Ridge) regularization shrinks weights smoothly toward zero",
            "L1 performs implicit feature selection",
            "L2 is more stable with correlated features"
        ],
        "negative_answers": [
            "L1 and L2 regularization produce identical results",
            "L1 regularization cannot eliminate features",
            "L2 regularization drives all weights to exactly zero",
            "regularization is never necessary for good model performance"
        ]
    },
    {
        "question": "How does positional encoding help transformers understand word order?",
        "answers": [
            "positional encodings add information about token positions in the sequence",
            "they enable transformers to capture sequential relationships without recurrence",
            "each position gets a unique encoding based on sine/cosine functions",
            "without positional encodings, word order would be irrelevant"
        ],
        "negative_answers": [
            "positional encoding is only needed for RNNs",
            "transformers inherently understand word order without encoding",
            "positional encodings modify the word embeddings permanently",
            "all tokens receive identical positional encoding"
        ]
    },
    {
        "question": "What are the key differences between classification and regression?",
        "answers": [
            "classification predicts discrete categories or classes",
            "regression predicts continuous numerical values",
            "classification uses softmax or sigmoid for outputs",
            "regression typically uses mean squared error as loss"
        ],
        "negative_answers": [
            "both tasks produce identical types of predictions",
            "classification is always more accurate than regression",
            "regression only works with linear relationships",
            "the choice between them does not affect model architecture"
        ]
    },
    {
        "question": "How does feature engineering improve machine learning models?",
        "answers": [
            "it creates new features from raw data to improve model performance",
            "techniques include scaling, encoding, and polynomial features",
            "good features can be more important than model complexity",
            "domain knowledge guides effective feature engineering"
        ],
        "negative_answers": [
            "raw features are always optimal without any preprocessing",
            "feature engineering is only necessary for shallow models",
            "removing features always improves model performance",
            "automated feature selection can never outperform manual engineering"
        ]
    },
    {
        "question": "What is the relationship between batch size and learning rate?",
        "answers": [
            "larger batch sizes typically require higher learning rates",
            "smaller batches update weights more frequently but noisily",
            "learning rate should scale with batch size for stable training",
            "batch size affects gradient noise and convergence behavior"
        ],
        "negative_answers": [
            "batch size and learning rate are completely independent",
            "the same learning rate works for all batch sizes",
            "larger batch sizes always require smaller learning rates",
            "batch size only affects computational efficiency, not optimization"
        ]
    },
    {
        "question": "How do skip connections (residual connections) help deep networks?",
        "answers": [
            "they allow gradients to flow more directly through deep networks",
            "they reduce the vanishing gradient problem",
            "they enable training of very deep networks (50+ layers)",
            "they help preserve information from earlier layers"
        ],
        "negative_answers": [
            "skip connections are only decorative with no functional purpose",
            "they prevent neural networks from learning useful features",
            "deep networks without skip connections train equally well",
            "skip connections are only useful for very shallow networks"
        ]
    },
    {
        "question": "What is zero-shot and few-shot learning in large language models?",
        "answers": [
            "zero-shot learning performs tasks without any in-context examples",
            "few-shot learning provides a few examples in the prompt for guidance",
            "few-shot generally performs better than zero-shot on complex tasks",
            "both leverage the model's pre-training knowledge"
        ],
        "negative_answers": [
            "zero-shot and few-shot learning are identical methods",
            "few-shot learning always outperforms fine-tuning",
            "zero-shot learning never works for any practical tasks",
            "these techniques require additional model training"
        ]
    },
    {
        "question": "How does ensemble learning improve predictions?",
        "answers": [
            "it combines multiple models to make better predictions",
            "averaging predictions from diverse models reduces overfitting",
            "ensemble methods include bagging, boosting, and stacking",
            "ensembles often outperform individual models significantly"
        ],
        "negative_answers": [
            "ensemble learning requires identical model architectures",
            "combining weak models cannot produce strong predictions",
            "ensemble methods only work for classification, not regression",
            "single well-tuned models always outperform ensembles"
        ]
    },
    {
        "question": "What is the curse of dimensionality and how does it affect machine learning?",
        "answers": [
            "it refers to problems that arise when working with high-dimensional data",
            "sparse data in high dimensions requires exponentially more samples",
            "dimensionality reduction techniques help address this problem",
            "feature selection focuses on the most relevant features"
        ],
        "negative_answers": [
            "more dimensions always improve model performance",
            "the curse of dimensionality only affects simple models",
            "high-dimensional data requires no special handling",
            "dimensionality reduction always loses important information"
        ]
    },
    {
        "question": "How do self-supervised learning methods work?",
        "answers": [
            "they create labels automatically from the data itself",
            "contrastive learning learns by contrasting similar and dissimilar examples",
            "masked language modeling predicts hidden tokens as a self-supervised task",
            "self-supervised pre-training provides useful representations"
        ],
        "negative_answers": [
            "self-supervised learning requires human-labeled data",
            "it is the same as unsupervised learning",
            "self-supervised learning cannot scale to large datasets",
            "representations from self-supervised learning are always weaker"
        ]
    },
    {
        "question": "What is the purpose of layer normalization in transformers?",
        "answers": [
            "it normalizes layer inputs to stabilize training",
            "it works per-sample unlike batch normalization",
            "it is essential for transformer models where batch size varies",
            "it helps with stable training in sequence models"
        ],
        "negative_answers": [
            "layer normalization is the same as batch normalization",
            "it is not needed if you use batch normalization",
            "layer normalization only works for very deep networks",
            "it increases computational cost during inference"
        ]
    },
    {
        "question": "How do vector databases enable similarity search?",
        "answers": [
            "they index embeddings using approximate nearest neighbor algorithms",
            "cosine similarity and Euclidean distance measure vector similarity",
            "FAISS and HNSW algorithms enable fast retrieval from large databases",
            "vector search is used for semantic search and recommendation systems"
        ],
        "negative_answers": [
            "vector databases require exact nearest neighbor search",
            "similarity search is slower than traditional keyword search",
            "embeddings must be identical for similarity matching",
            "vector databases are only useful for text data"
        ]
    },
    {
        "question": "What is multi-head attention and why is it important?",
        "answers": [
            "it computes multiple attention patterns in parallel",
            "each head can focus on different aspects of the input",
            "it increases model capacity without excessive parameter growth",
            "different heads learn different types of relationships"
        ],
        "negative_answers": [
            "multi-head attention is the same as single-head attention",
            "only one attention head is ever used in practice",
            "additional heads do not improve model performance",
            "multi-head attention requires much more computation than single-head"
        ]
    },
    {
        "question": "How does causal masking work in autoregressive models?",
        "answers": [
            "it prevents attention to future tokens during sequence generation",
            "it maintains the autoregressive property where each token depends only on past tokens",
            "it is essential for next-token prediction in language models",
            "future positions are set to negative infinity in attention scores"
        ],
        "negative_answers": [
            "causal masking allows models to see future tokens",
            "it is only needed for inference, not training",
            "autoregressive models work without causal masking",
            "masking reduces model expressiveness"
        ]
    }
]